# neural-tangents_extension


## Overview


This package is an extension of the Neural Tangents library (URL: https://github.com/google/neural-tangents). We added new features to support the kernel computation in the context of solving differential equations. For the complexity of the cost function, a set of methods are implemented to aid the construction of the partitioned kernel matrices. Traditional numerical methods including RBF interpolation collocation methods and a naive implementation of the Finite Element method are also included in this extension. See the example notebooks for more information.


## Symbols


The Neural Tangent Kernel (NTK) approximate the outputs of a wide neural network as a Gaussian process.
The matrix $\Theta(\mathcal X,\mathcal X)$ is referred to as `kernel_train_train` or `kdd`, and the matrix $\Theta(x,\mathcal X)$ is referred to as `kernel_test_train` or `ktd` following the naming convention of Neural Tangents. In the context of neural network solver for differential equations, these matrices are more complex. When solving a differential equation, the matrices `kdd` and `ktd` become block matrices, and take different forms, in contrast to the original usage of NTK where both matrices are generated by a single covariance function.